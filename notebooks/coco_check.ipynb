{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A notebook to check the performance of OVIS on COCO novel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The the class embeddings to match the saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/betray/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import mmcv\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BETRAY_PATH = \"/jupyter-users-home/tan-2enguyen/betrayed-by-captions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BETRAY_PATH not in sys.path:\n",
    "    sys.path.append(BETRAY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_class_file = '../datasets/unknown/known_65.txt'\n",
    "class_emb_file = '../datasets/embeddings/coco_class_with_bert_emb.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_client = mmcv.FileClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_known_classes = file_client.get_text(known_class_file).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/betray/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from open_set.models.utils.bert_embeddings import BertEmbeddings, BERT_MODEL_BY_EMBEDDING_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_type = 'bert'\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL_BY_EMBEDDING_TYPES[emb_type])\n",
    "bert_embeddings = BertEmbeddings(\n",
    "    bert_model=transformers.AutoModel.from_pretrained(BERT_MODEL_BY_EMBEDDING_TYPES[emb_type]).eval(),\n",
    ")\n",
    "\n",
    "for param in bert_embeddings.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts_by_name = {name: len(tokenizer.encode(name, add_special_tokens=False)) for name in all_known_classes} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person': 1,\n",
       " 'bicycle': 1,\n",
       " 'car': 1,\n",
       " 'motorcycle': 1,\n",
       " 'truck': 1,\n",
       " 'boat': 1,\n",
       " 'bench': 1,\n",
       " 'bird': 1,\n",
       " 'horse': 1,\n",
       " 'sheep': 1,\n",
       " 'zebra': 1,\n",
       " 'giraffe': 3,\n",
       " 'backpack': 1,\n",
       " 'handbag': 2,\n",
       " 'skis': 2,\n",
       " 'kite': 1,\n",
       " 'surfboard': 2,\n",
       " 'bottle': 1,\n",
       " 'spoon': 1,\n",
       " 'bowl': 1,\n",
       " 'banana': 1,\n",
       " 'apple': 1,\n",
       " 'orange': 1,\n",
       " 'broccoli': 3,\n",
       " 'carrot': 1,\n",
       " 'pizza': 1,\n",
       " 'donut': 2,\n",
       " 'chair': 1,\n",
       " 'bed': 1,\n",
       " 'tv': 1,\n",
       " 'laptop': 1,\n",
       " 'remote': 1,\n",
       " 'microwave': 1,\n",
       " 'oven': 1,\n",
       " 'refrigerator': 1,\n",
       " 'book': 1,\n",
       " 'clock': 1,\n",
       " 'vase': 1,\n",
       " 'toothbrush': 2,\n",
       " 'train': 1,\n",
       " 'bear': 1,\n",
       " 'suitcase': 1,\n",
       " 'frisbee': 3,\n",
       " 'fork': 1,\n",
       " 'sandwich': 1,\n",
       " 'toilet': 1,\n",
       " 'mouse': 1,\n",
       " 'toaster': 2,\n",
       " 'bus': 1,\n",
       " 'dog': 1,\n",
       " 'cow': 1,\n",
       " 'elephant': 1,\n",
       " 'umbrella': 1,\n",
       " 'tie': 1,\n",
       " 'skateboard': 2,\n",
       " 'cup': 1,\n",
       " 'knife': 1,\n",
       " 'cake': 1,\n",
       " 'couch': 1,\n",
       " 'keyboard': 1,\n",
       " 'sink': 1,\n",
       " 'scissors': 1,\n",
       " 'airplane': 1,\n",
       " 'cat': 1,\n",
       " 'snowboard': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 4904]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('donut',  add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = \"hat man donut\".split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6045]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(bar,  add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_known_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m embs_by_name \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     name: bert_embeddings\u001b[38;5;241m.\u001b[39mcalculate_word_embeddings(\n\u001b[1;32m      3\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(tokenizer\u001b[38;5;241m.\u001b[39mencode(name, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))  \u001b[38;5;66;03m# The [] is key, note that the tokenizing of ['fristbee'] and 'fristbee' have very different lengths\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m         )\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_known_classes\u001b[49m\n\u001b[1;32m      5\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_known_classes' is not defined"
     ]
    }
   ],
   "source": [
    "embs_by_name = {\n",
    "    name: bert_embeddings.calculate_word_embeddings(\n",
    "        torch.tensor(tokenizer.encode(name, add_special_tokens=False))  # The [] is key, note that the tokenizing of ['fristbee'] and 'fristbee' have very different lengths\n",
    "        ).mean(dim=0) for name in all_known_classes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_embs_by_name = {x['name']: torch.tensor(x['emb']) for x in mmcv.load(class_emb_file) if x['name'] in embs_by_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_name = {k: torch.norm(v - gt_embs_by_name[k], p='fro') for k, v in embs_by_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person': tensor(0.),\n",
       " 'bicycle': tensor(0.),\n",
       " 'car': tensor(0.),\n",
       " 'motorcycle': tensor(1.7268e-06),\n",
       " 'truck': tensor(3.3101e-06),\n",
       " 'boat': tensor(1.6852e-06),\n",
       " 'bench': tensor(0.),\n",
       " 'bird': tensor(0.),\n",
       " 'horse': tensor(0.),\n",
       " 'sheep': tensor(0.),\n",
       " 'zebra': tensor(0.),\n",
       " 'giraffe': tensor(1.1234e-06),\n",
       " 'backpack': tensor(0.),\n",
       " 'handbag': tensor(0.),\n",
       " 'skis': tensor(0.),\n",
       " 'kite': tensor(0.),\n",
       " 'surfboard': tensor(0.),\n",
       " 'bottle': tensor(0.),\n",
       " 'spoon': tensor(3.8716e-06),\n",
       " 'bowl': tensor(1.7392e-06),\n",
       " 'banana': tensor(0.),\n",
       " 'apple': tensor(0.),\n",
       " 'orange': tensor(1.6809e-06),\n",
       " 'broccoli': tensor(1.0401e-06),\n",
       " 'carrot': tensor(0.),\n",
       " 'pizza': tensor(1.7574e-06),\n",
       " 'donut': tensor(1.0273e-06),\n",
       " 'chair': tensor(0.),\n",
       " 'bed': tensor(0.),\n",
       " 'tv': tensor(0.),\n",
       " 'laptop': tensor(0.),\n",
       " 'remote': tensor(0.),\n",
       " 'microwave': tensor(0.),\n",
       " 'oven': tensor(1.6289e-06),\n",
       " 'refrigerator': tensor(1.7703e-06),\n",
       " 'book': tensor(0.),\n",
       " 'clock': tensor(0.),\n",
       " 'vase': tensor(0.),\n",
       " 'toothbrush': tensor(0.),\n",
       " 'train': tensor(0.),\n",
       " 'bear': tensor(2.1258e-06),\n",
       " 'suitcase': tensor(1.6771e-06),\n",
       " 'frisbee': tensor(1.9736e-06),\n",
       " 'fork': tensor(1.6896e-06),\n",
       " 'sandwich': tensor(0.),\n",
       " 'toilet': tensor(0.),\n",
       " 'mouse': tensor(1.7566e-06),\n",
       " 'toaster': tensor(0.),\n",
       " 'bus': tensor(0.),\n",
       " 'dog': tensor(1.7765e-06),\n",
       " 'cow': tensor(1.7731e-06),\n",
       " 'elephant': tensor(1.7659e-06),\n",
       " 'umbrella': tensor(0.),\n",
       " 'tie': tensor(2.2085e-06),\n",
       " 'skateboard': tensor(0.),\n",
       " 'cup': tensor(0.),\n",
       " 'knife': tensor(0.),\n",
       " 'cake': tensor(0.),\n",
       " 'couch': tensor(1.8417e-06),\n",
       " 'keyboard': tensor(0.),\n",
       " 'sink': tensor(0.),\n",
       " 'scissors': tensor(0.),\n",
       " 'airplane': tensor(0.),\n",
       " 'cat': tensor(0.),\n",
       " 'snowboard': tensor(0.)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct values should have error close to 0.\n",
    "error_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0898, -1.2682, -0.0260,  0.8309, -0.1939,  1.1347, -0.3817,  0.0976,\n",
       "         0.1264, -0.4558])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_by_name['skateboard'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0898, -1.2682, -0.0260,  0.8309, -0.1939,  1.1347, -0.3817,  0.0976,\n",
       "         0.1264, -0.4558])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_embs_by_name['skateboard'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the tokenization with a list vs. a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 3259]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrong behavior\n",
    "tokenizer.encode([\"donut\", \"paper\"], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 4904, 3259]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct behavior\n",
    "tokenizer.encode(\"donut paper\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 4904]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"donut\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3259]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"paper\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "betray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
